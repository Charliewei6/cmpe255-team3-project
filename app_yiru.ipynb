{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64df9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57672406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4d3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from local archive/rating.csv\n",
    "def loadData():\n",
    "    ratings = pd.read_csv('archive/rating.csv', parse_dates=['timestamp'])\n",
    "    return ratings\n",
    "\n",
    "ratings = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3959281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a percentage of data. In the following program, only use num% of raw data.\n",
    "cutDataPercent = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6e08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use num% of data, here we use 30%\n",
    "def cutData(num, ratings):\n",
    "    rand_userIds = np.random.choice(ratings['userId'].unique(), size=int(len(ratings['userId'].unique())*num), replace=False)\n",
    "    ratings = ratings.loc[ratings['userId'].isin(rand_userIds)]\n",
    "    return ratings\n",
    "\n",
    "ratings = cutData(cutDataPercent, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047718f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId  movieId  rating           timestamp\n",
      "236       3        1     4.0 1999-12-11 13:36:47\n",
      "237       3       24     3.0 1999-12-14 12:54:08\n",
      "238       3       32     4.0 1999-12-11 13:14:07\n",
      "239       3       50     5.0 1999-12-11 13:13:38\n",
      "240       3      160     3.0 1999-12-14 12:54:08\n"
     ]
    }
   ],
   "source": [
    "# show dataframe: ratings head\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8687c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6027314, 4)\n"
     ]
    }
   ],
   "source": [
    "# ratings shape, 6027314 rows and 4 columns\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b66b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41547\n"
     ]
    }
   ],
   "source": [
    "# ratings has 41547 unique users\n",
    "print(len(pd.unique(ratings['userId'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14834d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21917\n"
     ]
    }
   ],
   "source": [
    "# ratings has 21917 unique movies\n",
    "print(len(pd.unique(ratings['movieId'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5074b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275.0063421088653\n"
     ]
    }
   ],
   "source": [
    "# each user rated 275 movies on average\n",
    "print(ratings.shape[0] / len(pd.unique(ratings['movieId'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f39944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test according to the timestamp. \n",
    "# the latest rating interaction between a user and a movie is a test sample\n",
    "def trainTestSplit(ratings):\n",
    "    ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'].rank(method = 'first', ascending=False)\n",
    "    train_ratings = ratings[ratings['rank_latest'] != 1]\n",
    "    test_ratings = ratings[ratings['rank_latest'] == 1]\n",
    "    train_ratings = train_ratings[['userId', 'movieId', 'rating']]\n",
    "    test_ratings = test_ratings[['userId', 'movieId', 'rating']]\n",
    "    return train_ratings, test_ratings\n",
    "\n",
    "train_ratings, test_ratings = trainTestSplit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a59408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5985767, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ea67569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41547, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5e8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006940965126106646\n"
     ]
    }
   ],
   "source": [
    "# the number of test samples is equalt to about 0.694% the number of train samples\n",
    "print(test_ratings.shape[0] / train_ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64579031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId  movieId  rating\n",
      "236       3        1     4.0\n",
      "237       3       24     3.0\n",
      "238       3       32     4.0\n",
      "239       3       50     5.0\n",
      "240       3      160     3.0\n"
     ]
    }
   ],
   "source": [
    "# we get rid of the timestamp columns now\n",
    "print(train_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fbb1256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138492\n",
      "131259\n",
      "[    1    24    32 ... 63692 73202 86664]\n"
     ]
    }
   ],
   "source": [
    "# getting the maximum of userId and movieId and all unique movieId\n",
    "# valuables will be used later\n",
    "num_users = ratings['userId'].max()+1\n",
    "num_items = ratings['movieId'].max()+1\n",
    "all_movieIds = ratings['movieId'].unique()\n",
    "print(num_users)\n",
    "print(num_items)\n",
    "print(all_movieIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38dad2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          userId  movieId  rating\n",
      "16817522  116317     3464       1\n",
      "9236185    63832     1333       1\n",
      "11659680   80516    54286       1\n",
      "14469299   99977    48516       1\n",
      "865895      5784     5387       1\n"
     ]
    }
   ],
   "source": [
    "# presentation:\n",
    "# Baseline example\n",
    "# converting the dataset into an implicit feedback dataset\n",
    "# label all ratings as 1\n",
    "present1_train_rating = train_ratings\n",
    "present1_train_rating.loc[:, 'rating'] = 1\n",
    "print(present1_train_rating.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b9f5ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  0.5\n",
      "0       3  4.0\n",
      "1       6  4.0\n",
      "2      10  4.0\n",
      "3      11  4.5\n",
      "4      17  4.0\n"
     ]
    }
   ],
   "source": [
    "# presentation:\n",
    "# Improved example:\n",
    "# we designed to keep the rating value\n",
    "# but only label these ratings that are greater than the user's quantile(num) value to 1\n",
    "# In this case, we do one more step than the baseline example\n",
    "# our defined implicit feedback dataset makes sure that users like the movie\n",
    "user_rating_set = ratings[['userId', 'rating']]\n",
    "user_rating = user_rating_set.groupby('userId')['rating'].quantile([0.5]).unstack().reset_index()\n",
    "print(user_rating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b5c9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  0.25\n",
      "0       3   4.0\n",
      "1       6   3.0\n",
      "2      10   4.0\n",
      "3      11   3.5\n",
      "4      17   4.0\n"
     ]
    }
   ],
   "source": [
    "# Another try with quantile value settings to 0.25\n",
    "# we can see that userId 6 and 11 has a lower like movie rating number \n",
    "user_rating = user_rating_set.groupby('userId')['rating'].quantile([0.25]).unstack().reset_index()\n",
    "print(user_rating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc51a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our designed algorithms, we labeled the rating of the train_rating dataset to 1\n",
    "# when the rating value is greater than the user's quantile(num) rating value\n",
    "# for example:\n",
    "present2_train_rating = train_ratings\n",
    "\n",
    "rating_q = {}\n",
    "for i in range(len(user_rating)):\n",
    "    rating_q[user_rating.iloc[i][0]] = user_rating.iloc[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08ab2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(present2_train_rating)):\n",
    "    if present2_train_rating.iloc[i]['rating'] >= rating_q[present2_train_rating.iloc[i]['userId']]:\n",
    "        present2_train_rating.iloc[i]['rating'] = 1\n",
    "    else:\n",
    "        present2_train_rating.iloc[i]['rating'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01ad3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          userId  movieId  rating\n",
      "6823733    46956      529       0\n",
      "12464981   86121     1207       0\n",
      "15309064  105836     1912       0\n",
      "10722756   74142    79166       1\n",
      "14249366   98420     3698       0\n"
     ]
    }
   ],
   "source": [
    "# here is a random sample that one rating is labeled to 1 with our algorithm\n",
    "print(present2_train_rating.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f9744e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far, we have successfully generated our label 1 (positive) samples\n",
    "# now, we are going to add label 0 (negative) samples\n",
    "# here we set the ratio of the number of positive samples to the number of negative samples equals to 1:3\n",
    "ratio = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85d74698",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_users, present_items, present_labels = [], [], []\n",
    "present_user_item_set = set(zip(ratings['userId'], ratings['movieId']))\n",
    "ratio = 3\n",
    "for u, i in present_user_item_set:\n",
    "    present_users.append(u)\n",
    "    present_items.append(i)\n",
    "    present_labels.append(1)\n",
    "    for _ in range(ratio):\n",
    "        negative_item = np.random.choice(all_movieIds)\n",
    "        while (u, negative_item) in present_user_item_set:\n",
    "            negative_item = np.random.choice(all_movieIds)\n",
    "        present_users.append(u)\n",
    "        present_items.append(negative_item)\n",
    "        present_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "817bb63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users:5070 movieId:1270 label:1\n",
      "1 users:5070 movieId:25800 label:0\n",
      "2 users:5070 movieId:96724 label:0\n",
      "3 users:5070 movieId:3159 label:0\n",
      "4 users:12009 movieId:3476 label:1\n",
      "5 users:12009 movieId:43244 label:0\n",
      "6 users:12009 movieId:107079 label:0\n",
      "7 users:12009 movieId:89908 label:0\n",
      "8 users:109462 movieId:3265 label:1\n",
      "9 users:109462 movieId:113203 label:0\n",
      "10 users:109462 movieId:114760 label:0\n",
      "11 users:109462 movieId:980 label:0\n",
      "12 users:15617 movieId:1419 label:1\n",
      "13 users:15617 movieId:54262 label:0\n",
      "14 users:15617 movieId:8649 label:0\n",
      "15 users:15617 movieId:91503 label:0\n",
      "16 users:73201 movieId:435 label:1\n",
      "17 users:73201 movieId:108216 label:0\n",
      "18 users:73201 movieId:878 label:0\n",
      "19 users:73201 movieId:97946 label:0\n"
     ]
    }
   ],
   "source": [
    "# now our train dataset looked like this\n",
    "for i in range(20):\n",
    "    print(f\"{i} users:{present_users[i]} movieId:{present_items[i]} label:{present_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49315345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we combined our algorithm to the class MovieLensTrainDataset\n",
    "# besides the original base algorithm\n",
    "# we have our algorithms with other five different set of parameters:\n",
    "class MovieLensTrainDataset(Dataset):\n",
    "    \"\"\"MovieLens Pytorch Dataset for Training\n",
    "    Args:\n",
    "        ratings(pd.DataFrame): Dataframe containing the movie ratings\n",
    "        all_movieIds (list): List containing all movieIds\n",
    "    \"\"\"\n",
    "    def __init__(self, ratings, all_movieIds, algorithm):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds, algorithm)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self, ratings, all_movieIds, algorithm):\n",
    "        users, items, labels = [], [], []\n",
    "        \n",
    "        # Algorithm 1 is the BASELINE with number of negatives as 3\n",
    "        if algorithm == 1:\n",
    "            user_item_set = set(zip(ratings['userId'], ratings['movieId']))\n",
    "            num_negatives = 3\n",
    "            for u, i in user_item_set:\n",
    "                users.append(u)\n",
    "                items.append(i)\n",
    "                labels.append(1)\n",
    "                for _ in range(num_negatives):\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                    while (u, negative_item) in user_item_set:\n",
    "                        negative_item = np.random.choice(all_movieIds)\n",
    "                    users.append(u)\n",
    "                    items.append(negative_item)\n",
    "                    labels.append(0)\n",
    "        # Algorithm 2 is the first test with number of negatives as 2 and quantile 0.5\n",
    "        elif algorithm == 2:\n",
    "            user_item_set = set(zip(ratings['userId'], ratings['movieId'], ratings['rating']))\n",
    "            user_rating_set = ratings[['userId', 'rating']]\n",
    "            user_rating = user_rating_set.groupby('userId')['rating'].quantile([0.5]).unstack().reset_index()\n",
    "            rating_q = {}\n",
    "            num_negatives = 2\n",
    "            for i in range(len(user_rating)):\n",
    "                rating_q[user_rating.iloc[i][0]] = user_rating.iloc[i][1]\n",
    "            for u, i, r in user_item_set:\n",
    "                users.append(u)\n",
    "                items.append(i)\n",
    "                if r >= rating_q[u]:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "                for _ in range(num_negatives):\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                    while (u, negative_item, r) in user_item_set:\n",
    "                        negative_item = np.random.choice(all_movieIds)\n",
    "                    users.append(u)\n",
    "                    items.append(negative_item)\n",
    "                    labels.append(0)\n",
    "        # Algorithm 3 is the first test with number of negatives as 3 and quantile 0.25\n",
    "        elif algorithm == 3:\n",
    "            user_item_set = set(zip(ratings['userId'], ratings['movieId'], ratings['rating']))\n",
    "            user_rating_set = ratings[['userId', 'rating']]\n",
    "            user_rating = user_rating_set.groupby('userId')['rating'].quantile([0.25]).unstack().reset_index()\n",
    "            rating_q = {}\n",
    "            num_negatives = 3\n",
    "            for i in range(len(user_rating)):\n",
    "                rating_q[user_rating.iloc[i][0]] = user_rating.iloc[i][1]\n",
    "            for u, i, r in user_item_set:\n",
    "                users.append(u)\n",
    "                items.append(i)\n",
    "                if r >= rating_q[u]:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "                for _ in range(num_negatives):\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                    while (u, negative_item, r) in user_item_set:\n",
    "                        negative_item = np.random.choice(all_movieIds)\n",
    "                    users.append(u)\n",
    "                    items.append(negative_item)\n",
    "                    labels.append(0)\n",
    "        # Algorithm 4 is the first test with number of negatives as 4 and quantile 0.25\n",
    "        elif algorithm == 4:\n",
    "            user_item_set = set(zip(ratings['userId'], ratings['movieId'], ratings['rating']))\n",
    "            user_rating_set = ratings[['userId', 'rating']]\n",
    "            user_rating = user_rating_set.groupby('userId')['rating'].quantile([0.25]).unstack().reset_index()\n",
    "            rating_q = {}\n",
    "            num_negatives = 4\n",
    "            for i in range(len(user_rating)):\n",
    "                rating_q[user_rating.iloc[i][0]] = user_rating.iloc[i][1]\n",
    "            for u, i, r in user_item_set:\n",
    "                users.append(u)\n",
    "                items.append(i)\n",
    "                if r >= rating_q[u]:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "                for _ in range(num_negatives):\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                    while (u, negative_item, r) in user_item_set:\n",
    "                        negative_item = np.random.choice(all_movieIds)\n",
    "                    users.append(u)\n",
    "                    items.append(negative_item)\n",
    "                    labels.append(0)\n",
    "        # Algorithm 5 is the first test with number of negatives as 5 and quantile 0.25\n",
    "        elif algorithm == 5:\n",
    "            user_item_set = set(zip(ratings['userId'], ratings['movieId'], ratings['rating']))\n",
    "            user_rating_set = ratings[['userId', 'rating']]\n",
    "            user_rating = user_rating_set.groupby('userId')['rating'].quantile([0.25]).unstack().reset_index()\n",
    "            rating_q = {}\n",
    "            num_negatives = 5\n",
    "            for i in range(len(user_rating)):\n",
    "                rating_q[user_rating.iloc[i][0]] = user_rating.iloc[i][1]\n",
    "            for u, i, r in user_item_set:\n",
    "                users.append(u)\n",
    "                items.append(i)\n",
    "                if r >= rating_q[u]:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "                for _ in range(num_negatives):\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                    while (u, negative_item, r) in user_item_set:\n",
    "                        negative_item = np.random.choice(all_movieIds)\n",
    "                    users.append(u)\n",
    "                    items.append(negative_item)\n",
    "                    labels.append(0)\n",
    "        # Algorithm 6 is the first test with number of negatives as 6 and quantile 0.1\n",
    "        elif algorithm == 6:\n",
    "            user_item_set = set(zip(ratings['userId'], ratings['movieId'], ratings['rating']))\n",
    "            user_rating_set = ratings[['userId', 'rating']]\n",
    "            user_rating = user_rating_set.groupby('userId')['rating'].quantile([0.1]).unstack().reset_index()\n",
    "            rating_q = {}\n",
    "            num_negatives = 6\n",
    "            for i in range(len(user_rating)):\n",
    "                rating_q[user_rating.iloc[i][0]] = user_rating.iloc[i][1]\n",
    "            for u, i, r in user_item_set:\n",
    "                users.append(u)\n",
    "                items.append(i)\n",
    "                if r >= rating_q[u]:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "                for _ in range(num_negatives):\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                    while (u, negative_item, r) in user_item_set:\n",
    "                        negative_item = np.random.choice(all_movieIds)\n",
    "                    users.append(u)\n",
    "                    items.append(negative_item)\n",
    "                    labels.append(0)\n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f339d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next the following function is our model: Neural Collective Filter\n",
    "class NCF(pl.LightningModule):\n",
    "    \"\"\" Neural Collaborative Filtering (NCF)\n",
    "    \n",
    "        Args:\n",
    "            num_users (int): Number of unique users\n",
    "            num_items (int): Number of unique items\n",
    "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
    "            all_movieIds (list): List containing all movieIds (train + test)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, ratings, all_movieIds, algorithm):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.ratings = ratings\n",
    "        self.all_movieIds = all_movieIds\n",
    "        self.algorithm = algorithm\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        # Pass through embedding layers\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        # Concat the two embedding layers\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        # Pass through dense layer\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        # Output layer\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MovieLensTrainDataset(self.ratings, self.all_movieIds, self.algorithm), batch_size=512, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e40b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is our Test function\n",
    "# The method name is \"Hit 10\"\n",
    "def testing(ratings, test_ratings, all_movieIds, model):\n",
    "    # First, we get user-item pairs for testing\n",
    "    # Which we prepared earlier\n",
    "    # the test samples are users' latest rating\n",
    "    test_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
    "\n",
    "    # Next, we dict of all items that are interacted with by each user\n",
    "    user_interacted_items = ratings.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "    # Then, we create a hits list\n",
    "    # First, we know that for a user, the user rated movie A\n",
    "    # Next, we get the list of movies that the user never interactive with\n",
    "    # We then combine the 99 un-interactive negative samples with 1 test positive sample\n",
    "    # By running the NCF model, we will get a label value from 0 to 1 for each case\n",
    "    # The larger the label values is, the more positive the sample will be\n",
    "    # Therefore, we sort the result list, and then get the top 10 movies\n",
    "    # If the test sample movie is in the top 10 predicted movies, we treat the result as hit\n",
    "    hits = []\n",
    "    for (u,i) in test_user_item_set:\n",
    "        interacted_items = user_interacted_items[u]\n",
    "        not_interacted_items = set(all_movieIds) - set(interacted_items)\n",
    "        selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "        test_items = selected_not_interacted + [i]\n",
    "        \n",
    "        predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
    "                                            torch.tensor(test_items)).detach().numpy())\n",
    "        \n",
    "        top10_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "        \n",
    "        if i in top10_items:\n",
    "            hits.append(1)\n",
    "        else:\n",
    "            hits.append(0)\n",
    "            \n",
    "    # Finally, for all users, we get an average of their hits of a specific user.\n",
    "    # the higher the hit ratio is, the more presice our model is\n",
    "    print(\"The Hit Ratio @ 10 is {:.2f}\".format(np.average(hits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "345702d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | user_embedding | Embedding | 1.1 M \n",
      "1 | item_embedding | Embedding | 1.1 M \n",
      "2 | fc1            | Linear    | 1.1 K \n",
      "3 | fc2            | Linear    | 2.1 K \n",
      "4 | output         | Linear    | 33    \n",
      "---------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.645     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828b78f7595f4660a210f72caeef312a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 16688) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 16688) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4e3e1b24104d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer = pl.Trainer(max_epochs=5, gpus=None, reload_dataloaders_every_epoch=True,\n\u001b[1;32m      4\u001b[0m                  progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_movieIds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/profiler/profilers.py\u001b[0m in \u001b[0;36mprofile_iterable\u001b[0;34m(self, iterable, action_name)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mprefetch_iterator\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;31m# the iterator may be empty from the beginning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \"\"\"\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mrequest_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Recursively apply to collection items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/project-IkjfRVC8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 16688) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "print(\"Method1:\")\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds, algorithm=1)\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=None, reload_dataloaders_every_epoch=True,\n",
    "                 progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "testing(ratings, test_ratings, all_movieIds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a451087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method2:\")\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds, algorithm=2)\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=None, reload_dataloaders_every_epoch=True,\n",
    "                 progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "testing(ratings, test_ratings, all_movieIds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method3:\")\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds, algorithm=3)\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=None, reload_dataloaders_every_epoch=True,\n",
    "                 progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "testing(ratings, test_ratings, all_movieIds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f168d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method4:\")\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds, algorithm=4)\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=None, reload_dataloaders_every_epoch=True,\n",
    "                 progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "testing(ratings, test_ratings, all_movieIds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method5:\")\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds, algorithm=5)\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=None, reload_dataloaders_every_epoch=True,\n",
    "                 progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "testing(ratings, test_ratings, all_movieIds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method6:\")\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds, algorithm=6)\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=None, reload_dataloaders_every_epoch=True,\n",
    "                 progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "testing(ratings, test_ratings, all_movieIds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c25b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
